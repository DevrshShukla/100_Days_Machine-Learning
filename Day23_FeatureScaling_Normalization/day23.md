# ğŸ“Š Feature Scaling â€“ Normalization (Basic to Advanced)

Feature scaling is a **data preprocessing technique** used in Machine Learning to bring all numerical features to a **similar scale** so that no single feature dominates the model due to its large magnitude.

* Clear definitions
* Mathematical formulas
* Easy realâ€‘world examples
* When & where to use each technique

---

## ğŸ“Œ Table of Contents

1. What is Feature Scaling?
2. What is Normalization?
3. Why Normalization is Important
4. Types of Normalization

   * Min-Max Scaling
   * MaxAbs Scaling
   * Robust Scaling
5. Comparison Table
6. Which Normalization to Use & When
7. Key Takeaways

---

## 1ï¸âƒ£ What is Feature Scaling?

Feature Scaling is the process of **transforming numerical data** so that features lie within a **specific range or distribution**.

### âŒ Problem without scaling

| Feature | Example Values     |
| ------- | ------------------ |
| Age     | 18 â€“ 65            |
| Income  | 20,000 â€“ 10,00,000 |

ğŸ‘‰ Income will dominate Age during model training.

### âœ… Solution

Scale both features so they contribute **equally**.

---

## 2ï¸âƒ£ What is Normalization?

**Normalization** rescales feature values to a **fixed range**, usually **[0, 1]** or **[-1, 1]**.

ğŸ“Œ It preserves the **shape of the data distribution** while changing its scale.

---

## 3ï¸âƒ£ Why Normalization is Important?

âœ” Faster model convergence<br>
âœ” Improves performance of distanceâ€‘based algorithms<br>
âœ” Prevents large values from dominating<br>
âœ” Required for gradientâ€‘based optimization<br>

---

## 4ï¸âƒ£ Types of Normalization

---

## ğŸ”¹ 1. Min-Max Scaling

### ğŸ“– Definition

Transforms data to a **fixed range [0, 1]**.

### ğŸ“ Mathematical Formula

![alt text](image.png)
Where:

* X = original value
* Xmin = minimum value of feature
* Xmax = maximum value of feature

---

### ğŸŒ Realâ€‘World Example

**Exam Scores:**
Scores = [40, 60, 80, 100]

For score = 60:
[
\frac{60 - 40}{100 - 40} = \frac{20}{60} = 0.33
]

ğŸ“Œ Output range â†’ **0 to 1**

---

### âœ… When to Use Minâ€‘Max Scaling

âœ” When data has **no outliers**
âœ” For **Neural Networks**
âœ” For **image pixel normalization**
âœ” When you need a **bounded range**

### âŒ When NOT to Use

âœ– If data contains **outliers**

---

## ğŸ”¹ 2. MaxAbs Scaling

### ğŸ“– Definition

Scales data by dividing by the **maximum absolute value**, resulting in values between **[-1, 1]**.

---

### ğŸ“ Mathematical Formula

![alt text](image-1.png)

Where:

* |Xmax| = maximum absolute value

---

### ğŸŒ Realâ€‘World Example

**Stock Price Change (%):**
Values = [-20, -10, 0, 10, 20]

For value = -10:
[
\frac{-10}{20} = -0.5
]

ğŸ“Œ Output range â†’ **[-1, 1]**

---

### âœ… When to Use MaxAbs Scaling

âœ” When data is **centered at 0**
âœ” For **sparse data** (NLP, TFâ€‘IDF)
âœ” When **sign matters** (+ / -)

### âŒ When NOT to Use

âœ– If data has extreme outliers

---

## ğŸ”¹ 3. Robust Scaling

### ğŸ“– Definition

Uses **median** and **interquartile range (IQR)** instead of mean and standard deviation.

ğŸ“Œ Highly **robust to outliers**.

---

### ğŸ“ Mathematical Formula

![alt text](image-2.png)

Where:

* IQR = Q3 âˆ’ Q1

---

### ğŸŒ Realâ€‘World Example

**House Prices (â‚¹):**
[20L, 22L, 24L, 25L, 200L]

Median = 24L
IQR = 25L âˆ’ 22L = 3L

For 25L:
[
\frac{25 - 24}{3} = 0.33
]

ğŸ“Œ Outlier (200L) has minimal effect

---

### âœ… When to Use Robust Scaling

âœ” Data contains **outliers**
âœ” Financial datasets
âœ” Realâ€‘world noisy data

### âŒ When NOT to Use

âœ– When data is already clean and normalized

---

## 5ï¸âƒ£ Comparison Table

| Scaling Method | Range    | Handles Outliers | Best For                   |
| -------------- | -------- | ---------------- | -------------------------- |
| Minâ€‘Max        | [0,1]    | âŒ No             | Neural Networks, Images    |
| MaxAbs         | [-1,1]   | âŒ No             | Sparse Data, NLP           |
| Robust         | No fixed | âœ… Yes            | Financial, Realâ€‘world data |

---

## 6ï¸âƒ£ Which Normalization to Use & When?

| Scenario                 | Recommended Method |
| ------------------------ | ------------------ |
| Image pixel values       | Minâ€‘Max            |
| NLP / Sparse matrices    | MaxAbs             |
| Financial data           | Robust             |
| Data without outliers    | Minâ€‘Max            |
| Data with extreme values | Robust             |

---

## 7ï¸âƒ£ Key Takeaways

âœ” Normalization improves model stability
âœ” Choose method based on **data distribution**
âœ” Outliers â†’ use **Robust Scaling**
âœ” Neural Networks â†’ prefer **Minâ€‘Max**

---

ğŸ“Œ **Author:** Devrsh Shukla
ğŸ“Œ **Use Case:** Academic Projects | ML Practice | GitHub Portfolio

â­ If you found this helpful, give the repo a **star**!
